{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import rnn\n",
    "import numpy as np\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded rnn.py\n",
      "loaded rnn.py\n"
     ]
    }
   ],
   "source": [
    "model = rnn.RnnMiniBatch(4,20,4, 0.1, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_short_train = np.load('data/short_input_data_train.npy')\n",
    "Y_short_train = np.load('data/short_output_data_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 sum of batch loss 177.523681694\n",
      "epoch 1 sum of batch loss 177.48554352\n",
      "epoch 2 sum of batch loss 177.691893753\n",
      "epoch 3 sum of batch loss 177.563792204\n",
      "epoch 4 sum of batch loss 178.14408077\n",
      "epoch 5 sum of batch loss 177.957183489\n",
      "epoch 6 sum of batch loss 177.540511266\n",
      "epoch 7 sum of batch loss 177.377308098\n",
      "epoch 8 sum of batch loss 177.258888596\n",
      "epoch 9 sum of batch loss 177.412432244\n",
      "epoch 10 sum of batch loss 177.337280984\n",
      "epoch 11 sum of batch loss 177.389136109\n",
      "epoch 12 sum of batch loss 177.645642582\n",
      "epoch 13 sum of batch loss 177.941111843\n",
      "epoch 14 sum of batch loss 177.353883035\n",
      "epoch 15 sum of batch loss 177.381758354\n",
      "epoch 16 sum of batch loss 177.357379156\n",
      "epoch 17 sum of batch loss 177.431330583\n",
      "epoch 18 sum of batch loss 177.385209364\n",
      "epoch 19 sum of batch loss 177.326741848\n",
      "epoch 20 sum of batch loss 177.406357034\n",
      "epoch 21 sum of batch loss 177.25622954\n",
      "epoch 22 sum of batch loss 177.475468699\n",
      "epoch 23 sum of batch loss 177.390901729\n",
      "epoch 24 sum of batch loss 177.467814887\n",
      "epoch 25 sum of batch loss 177.484651828\n",
      "epoch 26 sum of batch loss 177.508559701\n",
      "epoch 27 sum of batch loss 177.477891401\n",
      "epoch 28 sum of batch loss 177.325282804\n",
      "epoch 29 sum of batch loss 177.467764387\n",
      "epoch 30 sum of batch loss 177.375236938\n",
      "epoch 31 sum of batch loss 177.498870972\n",
      "epoch 32 sum of batch loss 177.363901823\n",
      "epoch 33 sum of batch loss 177.379797738\n",
      "epoch 34 sum of batch loss 177.402025674\n",
      "epoch 35 sum of batch loss 177.545996145\n",
      "epoch 36 sum of batch loss 177.385320288\n",
      "epoch 37 sum of batch loss 177.381540168\n",
      "epoch 38 sum of batch loss 177.392687697\n",
      "epoch 39 sum of batch loss 177.351455759\n",
      "epoch 40 sum of batch loss 177.617522229\n",
      "epoch 41 sum of batch loss 177.415384238\n",
      "epoch 42 sum of batch loss 177.426472543\n",
      "epoch 43 sum of batch loss 177.589736834\n",
      "epoch 44 sum of batch loss 177.541537957\n",
      "epoch 45 sum of batch loss 177.482088303\n",
      "epoch 46 sum of batch loss 177.435874261\n",
      "epoch 47 sum of batch loss 177.387747892\n",
      "epoch 48 sum of batch loss 177.440216686\n",
      "epoch 49 sum of batch loss 177.328921543\n",
      "epoch 50 sum of batch loss 177.354823187\n",
      "epoch 51 sum of batch loss 177.30082016\n",
      "epoch 52 sum of batch loss 177.462649978\n",
      "epoch 53 sum of batch loss 177.553747196\n",
      "epoch 54 sum of batch loss 177.548939506\n",
      "epoch 55 sum of batch loss 177.481533226\n",
      "epoch 56 sum of batch loss 177.355731366\n",
      "epoch 57 sum of batch loss 177.328395345\n",
      "epoch 58 sum of batch loss 177.432301822\n",
      "epoch 59 sum of batch loss 177.515296328\n",
      "epoch 60 sum of batch loss 177.298789933\n",
      "epoch 61 sum of batch loss 177.318608465\n",
      "epoch 62 sum of batch loss 177.539137753\n",
      "epoch 63 sum of batch loss 177.348966686\n",
      "epoch 64 sum of batch loss 177.288865958\n",
      "epoch 65 sum of batch loss 177.402977103\n",
      "epoch 66 sum of batch loss 177.365615025\n",
      "epoch 67 sum of batch loss 177.418901678\n",
      "epoch 68 sum of batch loss 177.408088098\n",
      "epoch 69 sum of batch loss 177.351170307\n",
      "epoch 70 sum of batch loss 177.346871802\n",
      "epoch 71 sum of batch loss 177.391943696\n",
      "epoch 72 sum of batch loss 177.401267481\n",
      "epoch 73 sum of batch loss 177.401094027\n",
      "epoch 74 sum of batch loss 177.302125453\n",
      "epoch 75 sum of batch loss 177.338680758\n",
      "epoch 76 sum of batch loss 177.387035384\n",
      "epoch 77 sum of batch loss 177.40847526\n",
      "epoch 78 sum of batch loss 177.373424408\n",
      "epoch 79 sum of batch loss 177.386919859\n",
      "epoch 80 sum of batch loss 177.382775096\n",
      "epoch 81 sum of batch loss 177.36505797\n",
      "epoch 82 sum of batch loss 177.443842014\n",
      "epoch 83 sum of batch loss 177.315904305\n",
      "epoch 84 sum of batch loss 177.274092036\n",
      "epoch 85 sum of batch loss 177.466764477\n",
      "epoch 86 sum of batch loss 177.198458998\n",
      "epoch 87 sum of batch loss 177.469143409\n",
      "epoch 88 sum of batch loss 177.396237099\n",
      "epoch 89 sum of batch loss 177.425581068\n",
      "epoch 90 sum of batch loss 177.411106705\n",
      "epoch 91 sum of batch loss 177.416690472\n",
      "epoch 92 sum of batch loss 177.246099426\n",
      "epoch 93 sum of batch loss 177.345250052\n",
      "epoch 94 sum of batch loss 177.392264197\n",
      "epoch 95 sum of batch loss 177.337785468\n",
      "epoch 96 sum of batch loss 177.235516328\n",
      "epoch 97 sum of batch loss 177.367459855\n",
      "epoch 98 sum of batch loss 177.200444604\n",
      "epoch 99 sum of batch loss 177.371430229\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    num_batch = len(X_short_train)/batch_size\n",
    "    for i in range(num_batch):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i+1) * (batch_size), len(X_short_train) -1)\n",
    "        X_train = X_short_train[start_idx:end_idx]\n",
    "        Y_train = Y_short_train[start_idx:end_idx]\n",
    "        #print X_train.shape, Y_train.shape, i, start_idx\n",
    "        #print model.debug(X_train, Y_train)\n",
    "        loss += model.train(X_train, Y_train) / num_batch\n",
    "    print \"epoch \"+str(epoch) + \" sum of batch loss \"+str(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "RnnMiniBatch instance has no attribute 'debug'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-41290e7c8831>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: RnnMiniBatch instance has no attribute 'debug'"
     ]
    }
   ],
   "source": [
    "model.debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "177 / 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
