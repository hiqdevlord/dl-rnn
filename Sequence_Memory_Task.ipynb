{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memorizing elements of a sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this task is to memorize some specific elements of a sequence a symbols with variable length. This toy example is useful to test the capacity of RNNs to keep representations in memory over long sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding for string of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load binary_code.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ALPHABET = np.asarray(list(\"abcd\"), dtype=object)\n",
    "\n",
    "\n",
    "def symbols_to_binarray(s, alphabet=ALPHABET, dtype=np.float32):\n",
    "    \"\"\"One-hot encode a sequence of symbols\n",
    "    \n",
    "    This numerical representation of a string of symbols is useful\n",
    "    to feed the data and expected labels to the input and output\n",
    "    layers of recurrent networks.\n",
    "    \"\"\"\n",
    "    alphabet = np.asarray(list(alphabet), dtype=object)\n",
    "    n_samples = len(s)\n",
    "    n_features = len(alphabet)\n",
    "\n",
    "    mapping = dict(zip(alphabet, range(n_features)))\n",
    "    \n",
    "    code = np.zeros((n_samples, n_features), dtype=dtype)\n",
    "    for i, e in enumerate(s):\n",
    "        code[i, mapping[e]] = 1.0\n",
    "    return code\n",
    "\n",
    "\n",
    "def binarray_to_symbols(code, alphabet=ALPHABET):\n",
    "    \"\"\"Convert encoded data by to a string of symbols\"\"\"\n",
    "    n_samples, n_features = code.shape\n",
    "    if n_features != len(alphabet):\n",
    "        raise ValueError(\n",
    "            \"code should have %d columns (instead of %d).\"\n",
    "            % (len(alphabet), n_features)\n",
    "        )\n",
    "\n",
    "    # Make sure that the alphabet is a numpy array of symbols\n",
    "    # to make it possible to leverage numpy fancy indexing\n",
    "    if not isinstance(alphabet, np.ndarray):\n",
    "        alphabet = np.asarray(list(alphabet), dtype='object')\n",
    "\n",
    "    return \"\".join(alphabet[code.argmax(axis=1)])\n",
    "\n",
    "\n",
    "def plot_binary_tape(encoded_sequence, alphabet=ALPHABET):\n",
    "    plt.matshow(encoded_sequence, cmap=plt.cm.gray)\n",
    "    plt.xticks(np.arange(len(alphabet)), alphabet)\n",
    "    \n",
    "\n",
    "def plot_parallel_tapes(input_data, output_data,\n",
    "                        input_symbols, output_symbols):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5, 10))\n",
    "    for ax, data in zip(axes, [input_data, output_data]):\n",
    "        ax.matshow(data, cmap=plt.cm.gray)\n",
    "        ax.set_xticks(np.arange(len(ALPHABET)))\n",
    "        ax.set_xticklabels(ALPHABET, fontsize=18)\n",
    "    fig.tight_layout()\n",
    "    plt.title(\"input: %r, output: %r\" % (input_symbols, output_symbols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_sequence = \"abcdacbd\"\n",
    "encoded_sequence = symbols_to_binarray(symbol_sequence)\n",
    "encoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAHaCAYAAAAzC7QxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+oIPtZ4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105e95b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_binary_tape(encoded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAEzCAYAAAACQP57AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105efc890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_binary_tape(symbols_to_binarray('dcabd'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding back to a sequence of symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The `binary_to_symbols` function computes the inverse operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdacbd'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarray_to_symbols(encoded_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running count of symbols in a sequence\n",
    "\n",
    "Let's generate a dataset where the output tape should display the symbol that was the most frequent in the recent history of the input tape (over a fixed window size):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def running_max(encoded_input, window_size=3):\n",
    "    encoded_output = np.zeros_like(encoded_input)\n",
    "    for t in range(encoded_input.shape[0]):\n",
    "        window = encoded_input[t - window_size + 1 :t + 1]\n",
    "        frequencies = window.sum(axis=0)\n",
    "        winner = frequencies.argmax()\n",
    "        encoded_output[t, winner] = 1.\n",
    "    return encoded_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run this function on the binary represenation of an example string of symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = 'abbaabcddccab'\n",
    "input_data = symbols_to_binarray(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abbaabcddccab\n",
      "aabbaaabddcca\n"
     ]
    }
   ],
   "source": [
    "output_data = running_max(input_data)\n",
    "output_sequence = binarray_to_symbols(output_data)\n",
    "print(input_sequence)\n",
    "print(output_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAIZCAYAAAD3OXuwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105e95a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_parallel_tapes(input_data, output_data,\n",
    "                    input_sequence, output_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to work as expected. Note that in case of tie, 'a' is favored over 'b', 'b' over 'c' and so on. The function to learn is therefore fully deterministic. Let's generate a reference dataset for our RNN experiments.\n",
    "\n",
    "For let's start with random input sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sequences(n_sequences=1000, min_length=5, max_length=15,\n",
    "                       alphabet=ALPHABET, seed=None):\n",
    "    sequences = []\n",
    "    rng = np.random.RandomState(seed)\n",
    "    for i in range(n_sequences):\n",
    "        length = rng.randint(min_length, max_length)\n",
    "        sequences.append(\"\".join(rng.choice(ALPHABET, length)))\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['addddbdbca', 'caaacbcddcab', 'bbabadadbc', 'cdabd', 'dcdabbbd']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sequences(n_sequences=5, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `seed` parameter makes possible to control the random number generator to get seemingly random yet reproducible deterministic outcomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['addddbdbca', 'caaacbcddcab', 'bbabadadbc', 'cdabd', 'dcdabbbd']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sequences(n_sequences=5, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daadbdbdaa', 'adbacb', 'acbcada', 'addbbdc', 'cbbbd']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sequences(n_sequences=5, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have random input sequences, we can compute the expected ouput for each of them and generate a full dataset to train our networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_running_max_task_data(n_sequences=1000, min_length=5,\n",
    "                                   max_length=15, window_size=3,\n",
    "                                   alphabet=ALPHABET, seed=None):\n",
    "    \n",
    "    # Generate the input sequences as symbols\n",
    "    input_sequences = generate_sequences(\n",
    "        n_sequences=n_sequences, min_length=min_length,\n",
    "        max_length=max_length, alphabet=alphabet, seed=seed)\n",
    "    output_sequences = []\n",
    "\n",
    "    # Allocate all the data arrays at once and pad with zeros\n",
    "    n_features = len(alphabet)\n",
    "    input_data = np.zeros((n_sequences, max_length, n_features),\n",
    "                          dtype=np.float32)\n",
    "    output_data = np.zeros((n_sequences, max_length, n_features),\n",
    "                           dtype=np.float32)\n",
    "    \n",
    "    for sequence_idx, input_sequence in enumerate(input_sequences):\n",
    "        # store the encoded sequence to the input tape\n",
    "        encoded_input = symbols_to_binarray(input_sequence)\n",
    "        input_data[sequence_idx, 0:len(input_sequence)] = encoded_input\n",
    "        encoded_output = running_max(encoded_input,\n",
    "                                     window_size=window_size)\n",
    "        output_data[sequence_idx, 0:len(encoded_output)] = encoded_output\n",
    "        output_sequences.append(binarray_to_symbols(encoded_output))\n",
    "\n",
    "    return input_sequences, output_sequences, input_data, output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it to generate a toy dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_memory_task_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-77657b7c65b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m ) = generate_memory_task_data(n_sequences=10, seed=0)\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_memory_task_data' is not defined"
     ]
    }
   ],
   "source": [
    "(\n",
    "    input_sequences,\n",
    "    output_sequences,\n",
    "    input_data,\n",
    "    output_data,\n",
    ") = generate_memory_task_data(n_sequences=10, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip(input_sequences, output_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    plot_parallel_tapes(input_data[i], output_data[i],\n",
    "                        input_sequences[i], output_sequences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some reference data for this task with fixed random seeds to make it possible to compare the results of different study groups on the same data.\n",
    "\n",
    "We create 2 datasets, one with only short sequences (from 5 to 15 steps in the input sequence) and one with long sequences (from 20 to 50 steps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf data/running_max_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_specs = [\n",
    "    ('short', dict(min_length=5, max_length=15, window_size=3)),\n",
    "    ('long', dict(min_length=20, max_length=50, window_size=10)),\n",
    "]\n",
    "     \n",
    "fold_specs = [\n",
    "    ('train', dict(n_sequences=5000, seed=0)),\n",
    "    ('validation', dict(n_sequences=1000, seed=1)),\n",
    "    ('test', dict(n_sequences=1000, seed=2)),\n",
    "]\n",
    "\n",
    "data_folder = 'data/running_max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import os\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def write_dataset(data_folder, generate_data, dataset_specs, fold_specs):\n",
    "    if not op.isdir(data_folder):\n",
    "        os.makedirs(data_folder)\n",
    "\n",
    "    for combined_specs in product(dataset_specs, fold_specs):\n",
    "        ds_name, ds_params = combined_specs[0]\n",
    "        fold_name, fold_params = combined_specs[1]\n",
    "        params = {}\n",
    "        params.update(ds_params)\n",
    "        params.update(fold_params)\n",
    "\n",
    "        (input_sequences, output_sequences,\n",
    "         input_data, output_data) = generate_data(**params)\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "                'input': input_sequences,\n",
    "                'output': output_sequences,\n",
    "        })\n",
    "        fname = op.join(data_folder, '%s_sequence_%s.json'\n",
    "                        % (ds_name, fold_name))\n",
    "        print('Saving symbol sequences %s' % fname)\n",
    "        df.to_json(fname, orient='records')\n",
    "\n",
    "        for name, data in (('input', input_data), ('output', output_data)):\n",
    "            fname = op.join(data_folder, '%s_%s_data_%s.npy'\n",
    "                            % (ds_name, name, fold_name))\n",
    "            print('Saving data %s' % fname)\n",
    "            np.save(fname, data)\n",
    "\n",
    "\n",
    "\n",
    "write_dataset(data_folder, generate_running_max_task_data,\n",
    "              dataset_specs, fold_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "short_symbols_train = pd.read_json(\n",
    "    'data/running_max/short_sequence_train.json')\n",
    "short_symbols_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_short_train = np.load('data/running_max/short_input_data_train.npy')\n",
    "Y_short_train = np.load('data/running_max/short_output_data_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    plot_parallel_tapes(X_short_train[i], Y_short_train[i],\n",
    "                        short_symbols_train['input'][i],\n",
    "                        short_symbols_train['output'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data for a simple memory task\n",
    "\n",
    "The goal of this task is to output the 2nd and 5th element of random input sequences.\n",
    "\n",
    "To solve it, the RNN has to rember the current position (count the element of the sequence) and store some representation of the 2nd and 5th element in its recurrent layer activations.  This task can be made artificially hard by increasing the average lentgh of the sequences as it is likely to be harder to memorize old events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generate_sequences(n_sequences=5, min_length=5, max_length=15, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate the sequences as a data array padded with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_memory_task_data(n_sequences=1000, min_length=5,\n",
    "                              max_length=15, alphabet=ALPHABET,\n",
    "                              seed=None):\n",
    "    \n",
    "    # Generate the input sequences as symbols\n",
    "    input_sequences = generate_sequences(\n",
    "        n_sequences=n_sequences, min_length=min_length,\n",
    "        max_length=max_length, alphabet=alphabet, seed=seed)\n",
    "    output_sequences = []\n",
    "    \n",
    "    # 2 steps are used for the expected output\n",
    "    n_steps_per_sequence = (max_length + 2)\n",
    "\n",
    "    # Allocate all the data arrays at once and pad with zeros\n",
    "    n_features = len(alphabet)\n",
    "    input_data = np.zeros((n_sequences, n_steps_per_sequence, n_features),\n",
    "                          dtype=np.float32)\n",
    "    output_data = np.zeros((n_sequences, n_steps_per_sequence, n_features),\n",
    "                           dtype=np.float32)\n",
    "    \n",
    "    for sequence_idx, input_sequence in enumerate(input_sequences):\n",
    "        # store the encoded sequence to the input tape\n",
    "        encoded_input = symbols_to_binarray(input_sequence)\n",
    "        input_data[sequence_idx, 0:len(input_sequence)] = encoded_input\n",
    "        \n",
    "        # store the encoded output to the output tape by taking\n",
    "        # the 2nd and 5th symbols of the input sequence\n",
    "        output_sequence = input_sequence[1] + input_sequence[4]\n",
    "        output_sequences.append(output_sequence)\n",
    "        encoded_output = symbols_to_binarray(output_sequence)\n",
    "        start = len(input_sequence)\n",
    "        stop = start + 2\n",
    "        output_data[sequence_idx, start:stop] = encoded_output\n",
    "        \n",
    "    return input_sequences, output_sequences, input_data, output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some reference data for this task with fixed random seeds to make it possible to compare the results of different study groups on the same data.\n",
    "\n",
    "Again, we create 2 datasets, one with only short sequences (from 5 to 15 steps in the input sequence) and one with long sequences (from 20 to 50 steps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm -rf data/memory_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_specs = [\n",
    "    ('short', dict(min_length=5, max_length=15)),\n",
    "    ('long', dict(min_length=20, max_length=50)),\n",
    "]\n",
    "     \n",
    "fold_specs = [\n",
    "    ('train', dict(n_sequences=5000, seed=0)),\n",
    "    ('validation', dict(n_sequences=1000, seed=1)),\n",
    "    ('test', dict(n_sequences=1000, seed=2)),\n",
    "]\n",
    "\n",
    "data_folder = 'data/memory_task'\n",
    "write_dataset(data_folder, generate_memory_task_data,\n",
    "              dataset_specs, fold_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible to reload the save data using pandas for loading the symbolic data in the json files and numpy for the binary data in the `.npy` files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "short_symbols_train = pd.read_json(\n",
    "    'data/memory_task/short_sequence_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "short_symbols_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_short_train = np.load('data/memory_task/short_input_data_train.npy')\n",
    "Y_short_train = np.load('data/memory_task/short_output_data_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    plot_parallel_tapes(X_short_train[i], Y_short_train[i],\n",
    "                        short_symbols_train['input'][i],\n",
    "                        short_symbols_train['output'][i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
