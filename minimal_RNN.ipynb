{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal RNN notebook\n",
    "\n",
    "### RNN representation\n",
    "\n",
    "Contrary to a Feed Forward Neural Network, an RNN is a recurrent neural network, in which the information flow is not linear. A general representation can be seen as follows:\n",
    "\n",
    "![Representation](img/rnn_simple.svg)\n",
    "\n",
    "An RNN is useful to deal with sequential information: a sequence of inputs is fed through the network and the hidden state is updated at each step of the sequence. The sequence is commonly represented as a time sequence, and the most straight forward learning algorithm is backpropagation through time (BPTT) http://en.wikipedia.org/wiki/Backpropagation_through_time.\n",
    "\n",
    "To understand properly BPTT, a better representation of the RNN is its unfolded version:\n",
    "\n",
    "![Representation](img/rnn_unfolded.svg)\n",
    "\n",
    "The input X is a sequence $x_0, x_1, ... x_t$, at each time-step t a new input $x_t$ is fed to the network.\n",
    "\n",
    "### Equations\n",
    "\n",
    "The most simple forward equations for a RNN are as follows:\n",
    "\n",
    "$$h_t = \\tanh(x_t . W_{in} + h_{t-1} . W_{rec})$$\n",
    "$$y_t = softmax(h_t . W_{out})$$\n",
    "\n",
    "Depending on the problem, all the outputs $y_0, ... y_t$ might be useful, or just $y_t$ the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano import shared \n",
    "from collections import OrderedDict\n",
    "\n",
    "dtype=T.config.floatX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weight(shape, name, sample='uni'):\n",
    "    if sample=='unishape':\n",
    "        return shared(value=np.asarray(np.random.uniform(\n",
    "                low=-np.sqrt(6. / (shape[0] + shape[1])),\n",
    "                high=np.sqrt(6. / (shape[0] + shape[1])),\n",
    "                size=shape), dtype=dtype), \n",
    "                    name=name, borrow=True)\n",
    "    \n",
    "    if sample=='svd':\n",
    "        values = np.ndarray(shape, dtype=dtype)\n",
    "        for dx in xrange(shape[0]):\n",
    "            vals = np.random.uniform(low=-1., high=1.,  size=(shape[1],))\n",
    "            values[dx,:] = vals\n",
    "        _,svs,_ = np.linalg.svd(values)\n",
    "        #svs[0] is the largest singular value                      \n",
    "        values = values / svs[0]\n",
    "        return shared(values, name=name, borrow=True)\n",
    "    \n",
    "    if sample=='uni':\n",
    "        return shared(value=np.asarray(np.random.uniform(low=-0.1,high=0.1, size=shape), dtype=dtype), \n",
    "                      name=name, borrow=True)\n",
    "    \n",
    "    if sample=='zero':\n",
    "        return shared(value=np.zeros(shape=shape, dtype=dtype), \n",
    "                      name=name, borrow=True)\n",
    "    \n",
    "    \n",
    "    raise \"error bad sample technique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Rnn:\n",
    "    def __init__(self, n_in, n_hid, n_out, lr):   \n",
    "        self.n_in = n_in\n",
    "        self.n_hid = n_hid\n",
    "        self.n_out = n_out\n",
    "        self.W_in = init_weight((self.n_in, self.n_hid),'W_in', 'svd')\n",
    "        self.W_out = init_weight((self.n_hid, self.n_out),'W_out', 'svd')\n",
    "        self.W_rec = init_weight((self.n_hid, self.n_hid),'W_rec', 'svd')\n",
    "        self.b_out = init_weight((self.n_out), 'b_out','zero')\n",
    "        self.params = [self.W_in,self.W_out,self.W_rec, self.b_out]\n",
    "        \n",
    "        def step(x_t, h_tm1):\n",
    "            h_t = T.nnet.tanh(T.dot(x_t, self.W_in) + T.dot(h_tm1, self.W_rec))\n",
    "            y_t = T.nnet.softmax(- (T.dot(h_t, self.W_out) + self.b_out))            \n",
    "            return [h_t, y_t]\n",
    "\n",
    "        X = T.matrix() # X is the sequence of vector\n",
    "        Y = T.matrix() # Y is the output of vector\n",
    "        h0 = shared(np.zeros(self.n_hid, dtype=dtype)) # initial hidden state \n",
    "        y0 = shared(np.ones(self.n_out, dtype=dtype)) # starting output sequence\n",
    "        lr = shared(np.cast[dtype](lr))\n",
    "        \n",
    "        [h_vals, y_vals], _ = theano.scan(fn=step,                                  \n",
    "                                          sequences=X,\n",
    "                                          outputs_info=[h0, None])\n",
    "                \n",
    "        cost = -T.mean(Y * T.log(y_vals)+ (1.- Y) * T.log(1. - y_vals))\n",
    "        cost = T.nnet.binary_crossentropy(y_vals, Y)\n",
    "        \n",
    "        gparams = T.grad(cost, self.params)\n",
    "        updates = OrderedDict()\n",
    "        for param, gparam in zip(self.params, gparams):\n",
    "            updates[param] = param - gparam * lr\n",
    "        \n",
    "        self.train = theano.function(inputs = [X, Y], outputs = cost, updates=updates)\n",
    "        self.predictions = theano.function(inputs = [X], outputs = y_vals)                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RnnMiniBatch:\n",
    "    def __init__(self, n_in, n_hid, n_out, lr):   \n",
    "        self.n_in = n_in\n",
    "        self.n_hid = n_hid\n",
    "        self.n_out = n_out\n",
    "        self.W_in = init_weight((self.n_in, self.n_hid),'W_in')\n",
    "        self.W_out = init_weight((self.n_hid, self.n_out),'W_out')\n",
    "        self.W_rec = init_weight((self.n_hid, self.n_hid),'W_rec')\n",
    "        \n",
    "        \n",
    "        self.params = [self.W_in,self.W_out,self.W_rec]\n",
    "        \n",
    "        def step(x_t, h_tm1):\n",
    "            h_t = T.nnet.sigmoid(T.dot(x_t, self.W_in) + T.dot(h_tm1, self.W_rec))\n",
    "            y_t = T.nnet.softmax(T.dot(h_t, self.W_out))\n",
    "            return [h_t, y_t]\n",
    "\n",
    "\n",
    "        X = T.tensor3() # batch of sequence of vector\n",
    "        Y = T.matrix() # batch of output vector \n",
    "        h0 = shared(np.zeros(self.n_hid, dtype=dtype)) # initial hidden state \n",
    "        y0 = shared(np.ones(self.n_out, dtype=dtype)) # starting output sequence\n",
    "        lr = shared(np.cast[dtype](lr))\n",
    "        \n",
    "        [h_vals, y_vals], _ = theano.scan(fn=step,                                  \n",
    "                                          sequences=X,\n",
    "                                          outputs_info=[h0, None])\n",
    "        \n",
    "        \n",
    "        cost = - T.mean(Y * T.log(y_vals[-1,0,:]) + (1- Y) * T.log(1.-y_vals[-1,0,:]))\n",
    "        gparams = T.grad(cost, self.params)\n",
    "        updates = OrderedDict()\n",
    "        for param, gparam in zip(self.params, gparams):\n",
    "            updates[param] = param - gparam * lr\n",
    "        \n",
    "        self.train = theano.function(inputs = [X, Y], outputs = cost, updates=updates)\n",
    "        self.predictions = theano.function(inputs = [X], outputs = y_vals[-1,0,:])\n",
    "        \n",
    "        '''y_vals[:,-1]\n",
    "        y_pred = T.argmax(self.p_y_given_x, axis=1)\n",
    "        cost = - T.mean()\n",
    "        \n",
    "        gibbs10 = theano.function([sample], values[-1], updates=updates)'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/Theano-0.6.0-py2.7.egg/theano/tensor/opt.py:2213: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  if (replace_x == replace_y and\n",
      "/usr/local/lib/python2.7/dist-packages/Theano-0.6.0-py2.7.egg/theano/scan_module/scan_perform_ext.py:117: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n"
     ]
    }
   ],
   "source": [
    "model = Rnn(7, 50, 7, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.random.uniform(low=-0.1, high=0.1, size=(15,7)).astype(dtype=dtype) \n",
    "model.predictions(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X = np.random.uniform(low=-0.1, high=0.1, size=(100,15,10)).astype(dtype=dtype) \n",
    "Y = np.zeros(shape=(100,5)).astype(dtype=dtype)\n",
    "indices = np.random.randint(5, size=(100))\n",
    "for x in range(Y.shape[0]):\n",
    "    Y[x,indices[x]]=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.train(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_epochs = 100\n",
    "#stupid and naive sgd\n",
    "for x in range(nb_epochs):\n",
    "    error = 0.\n",
    "    for j in range(len(train_data)):  \n",
    "        index = np.random.randint(0, len(train_data))\n",
    "        i, o = train_data[index]\n",
    "        train_cost = model.train(i, o)\n",
    "        error += train_cost\n",
    "    if x%10==0:\n",
    "            print \"epoch \"+str(x)+ \" error: \"+str(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "chars='BTSXPVE'\n",
    "\n",
    "graph = [[(1,5),('T','P')] , [(1,2),('S','X')], \\\n",
    "           [(3,5),('S','X')], [(6,),('E')], \\\n",
    "           [(3,2),('V','P')], [(4,5),('V','T')] ]\n",
    "\n",
    "\n",
    "def in_grammar(word):\n",
    "    if word[0] != 'B':\n",
    "        return False\n",
    "    node = 0    \n",
    "    for c in word[1:]:\n",
    "        transitions = graph[node]\n",
    "        try:\n",
    "            node = transitions[0][transitions[1].index(c)]\n",
    "        except ValueError: # using exceptions for flow control in python is common\n",
    "            return False\n",
    "    return True        \n",
    "      \n",
    "def sequenceToWord(sequence):\n",
    "    \"\"\"\n",
    "    converts a sequence (one-hot) in a reber string\n",
    "    \"\"\"\n",
    "    reberString = ''\n",
    "    for s in sequence:\n",
    "        index = np.where(s==1.)[0][0]\n",
    "        reberString += chars[index]\n",
    "    return reberString\n",
    "    \n",
    "def generateSequences(minLength):\n",
    "    while True:\n",
    "        inchars = ['B']\n",
    "        node = 0\n",
    "        outchars = []    \n",
    "        while node != 6:\n",
    "            transitions = graph[node]\n",
    "            i = np.random.randint(0, len(transitions[0]))\n",
    "            inchars.append(transitions[1][i])\n",
    "            outchars.append(transitions[1])\n",
    "            node = transitions[0][i]\n",
    "        if len(inchars) > minLength:  \n",
    "            return inchars, outchars\n",
    "\n",
    "\n",
    "def get_one_example(minLength):\n",
    "    inchars, outchars = generateSequences(minLength)\n",
    "    inseq = []\n",
    "    outseq= []\n",
    "    for i,o in zip(inchars, outchars): \n",
    "        inpt = np.zeros(7)\n",
    "        inpt[chars.find(i)] = 1.     \n",
    "        outpt = np.zeros(7)\n",
    "        for oo in o:\n",
    "            outpt[chars.find(oo)] = 1.\n",
    "        inseq.append(inpt)\n",
    "        outseq.append(outpt)\n",
    "    return inseq, outseq\n",
    "\n",
    "\n",
    "def get_char_one_hot(char):\n",
    "    char_oh = np.zeros(7)\n",
    "    for c in char:\n",
    "        char_oh[chars.find(c)] = 1.\n",
    "    return [char_oh] \n",
    "    \n",
    "def get_n_examples(n, minLength=10):\n",
    "    examples = []\n",
    "    for i in xrange(n):\n",
    "        examples.append(get_one_example(minLength))\n",
    "    return examples\n",
    "\n",
    "emb_chars = \"TP\"\n",
    "\n",
    "\n",
    "def get_one_embedded_example(minLength=10):\n",
    "    i, o = get_one_example(minLength)\n",
    "    emb_char = emb_chars[np.random.randint(0, len(emb_chars))]\n",
    "    new_in = get_char_one_hot(('B',))\n",
    "    new_in += get_char_one_hot((emb_char,))\n",
    "    new_out= get_char_one_hot(emb_chars)\n",
    "    new_out+= get_char_one_hot('B',)\n",
    "    new_in += i\n",
    "    new_out += o\n",
    "    new_in += get_char_one_hot(('E',))\n",
    "    new_in += get_char_one_hot((emb_char,))\n",
    "    new_out += get_char_one_hot((emb_char, ))\n",
    "    new_out += get_char_one_hot(('E',))\n",
    "    return new_in, new_out\n",
    "    \n",
    "def get_n_embedded_examples(n, minLength=10):\n",
    "    examples = []\n",
    "    for i in xrange(n):\n",
    "        examples.append(get_one_embedded_example(minLength))\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = get_n_embedded_examples(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = get_n_embedded_examples(10)\n",
    "\n",
    "def print_out(test_data):\n",
    "    for i,o in test_data:\n",
    "        p = model.predictions(i)\n",
    "        print o[-2] # target\n",
    "        print np.asarray([0. if x!=np.argmax(p[-2]) else 1. for x in range(7)]) # prediction\n",
    "        print \n",
    "print_out(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[len(x[0]) for x in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# word prediction\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "from gensim import corpora\n",
    "\n",
    "\n",
    "def process(x):\n",
    "    return re.sub('\\W+', ' ', x).lower().split()\n",
    "\n",
    "\n",
    "class Corpus:\n",
    "    def __init__(self, seq_x=None, dic=None):                \n",
    "        self.seq_x = []\n",
    "        self.seq_y = []\n",
    "        self.matrix = []\n",
    "        self.idx2word = {}\n",
    "        self.word2idx = {}\n",
    "        if dic == None:\n",
    "            dictionary = corpora.Dictionary(process(line) for line in TextList + TitleList)\n",
    "            dictionary.filter_extremes(no_below=10,no_above=1.0, keep_n=100000)\n",
    "            dictionary.compactify()\n",
    "            self.idx2word = {k:v for (k,v) in dictionary.items()}\n",
    "            self.idx2word[len(self.idx2word)] = 'END'\n",
    "            self.word2idx = {v:k for (k,v) in self.idx2word.items()}\n",
    "            del dictionary\n",
    "        else:\n",
    "            self.idx2word = dic\n",
    "            self.idx2word[len(self.idx2word)] = 'END'\n",
    "            self.word2idx = {v:k for (k,v) in self.idx2word.items()}\n",
    "        self.vocsize = len(self.idx2word)\n",
    "\n",
    "        if seq_x!=None:\n",
    "            for line in seq_x:\n",
    "                words = filter(lambda w: w in self.word2idx, process(line))\n",
    "                self.seq_x.append(words)\n",
    "        '''for line in seq_y:\n",
    "            words = line.split()\n",
    "            self.seq_y.append(words)\n",
    "            words = filter(lambda w: w in dictionary, process(line))\n",
    "            self.seq_x.append(words)  \n",
    "            for word in words:\n",
    "                dic_freq[word] = dic_freq.get(word, 0) + 1'''\n",
    "        \n",
    "    def to_numpy(self):\n",
    "        \n",
    "        correct_seqs = [seq for seq in self.seq_x if len(seq) > 99]\n",
    "        self.matrix = np.zeros(shape=(len(correct_seqs), 100), dtype='int32')\n",
    "        for idx, seq in enumerate(correct_seqs):\n",
    "            seq_idxs = [self.word2idx[w] for w in seq[:100]]\n",
    "            if len(seq_idxs)<100:\n",
    "                continue\n",
    "            row = np.asarray(seq_idxs, dtype='int32')\n",
    "            self.matrix[idx,:] = row\n",
    "        return self.matrix\n",
    "        \n",
    "    def one_hot(self, x):\n",
    "        vec = np.zeros(size=(1,1,self.vocsize), dtype=dtype)\n",
    "        vec[1,1,x] = 1.0\n",
    "        return vec\n",
    "\n",
    "def make_dataset(matrix, pad, start=3, min_len=10, max_len=20):      \n",
    "    assert(start+max_len<matrix.shape[1])\n",
    "    dataset_x = np.ones(shape = (matrix.shape[0], max_len), dtype = 'int32') * pad\n",
    "    dataset_y = np.zeros(shape = (matrix.shape[0]), dtype = 'int32')        \n",
    "    for idx in range(matrix.shape[0]):\n",
    "        length = random.randint(min_len, max_len)\n",
    "\n",
    "        #pad with end seq                        \n",
    "        dataset_x[idx,0:length] = matrix[idx,start:start+length]    \n",
    "        dataset_y[idx] = matrix[idx,length]\n",
    "    return [dataset_x, dataset_y]\n",
    "        #voc = [k for (k,v) in dic_freq.items() if v>=min_freq]\n",
    "        #print \"loaded \"+ len(dic_freq) + \"words, kept \" + len(voc) + \"words\"\n",
    "        #self.idx_voc = {v:k for (k,v) in self.voc_idx.items()}\n",
    "        \n",
    "    #todo save / load\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "filename = \"/media/charles/data/articles\"\n",
    "h = open(filename)\n",
    "all_jsons=[]\n",
    "for line in h:    \n",
    "    if line[0]=='[':\n",
    "        all_jsons.append(line[:-1])\n",
    "        \n",
    "TitleList = []\n",
    "TextList = []\n",
    "IndexList = []\n",
    "count = 0\n",
    "\n",
    "for oneJson in all_jsons:\n",
    "    u = json.loads(oneJson)\n",
    "    for item in u:\n",
    "        fields = item['fields']\n",
    "        TitleList.append(fields['title'])\n",
    "        TextList.append(fields['text'])\n",
    "        IndexList.append(item['rowKey'])\n",
    "        count+=1\n",
    "        if count%10000==0:\n",
    "            print(\"done: \"+str(count))\n",
    "\n",
    "all_jsons = []\n",
    "del all_jsons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(TitleList), len(TextList)\n",
    "seq_x = corpus.seq_x\n",
    "dictionary = corpora.Dictionary(process(line) for line in TextList + TitleList)\n",
    "dictionary.filter_extremes(no_below=10,no_above=1.0, keep_n=100000)\n",
    "dictionary.compactify()\n",
    "dic = {k:v for (k,v) in dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = Corpus(seq_x=TextList, dic=None)\n",
    "#[dx, dy] = corpus.make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix = corpus.to_numpy()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
